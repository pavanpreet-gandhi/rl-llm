{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xchen/anaconda3/envs/dlp/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from rich.pretty import pprint\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "\n",
    "import gym\n",
    "import babyai_text\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer\n",
    "from trl import (\n",
    "    PPOConfig,\n",
    "    PPOTrainer,\n",
    "    AutoModelForCausalLMWithValueHead,\n",
    "    create_reference_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        # Training config\n",
    "        \"model_id\": \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        \"env_id\": \"BabyAI-MixedTrainLocal-v0\",\n",
    "        \"num_shared_layers\": None,\n",
    "        \"num_steps_train\": 2000,\n",
    "        \"num_envs\": 4,\n",
    "        \"seed\" : 30,\n",
    "        # PPO config\n",
    "        \"batch_size\": 4,\n",
    "        \"mini_batch_size\": 4,\n",
    "        # \"gradient_accumulation_steps\": 4, \n",
    "        \"optimize_device_cache\": True,\n",
    "        \"early_stopping\": False,\n",
    "        # Env config\n",
    "        \"consecutive_invalid_actions_allowed\": 5,\n",
    "        \"invalid_action_penalty\": -0.1,\n",
    "        \"max_steps_per_episode\": 100,\n",
    "        # Generation kwargs\n",
    "        \"max_new_tokens\": 10,\n",
    "        \"do_sample\": False,\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_k\": 20,\n",
    "        \"top_p\": 0.90,\n",
    "        # PEFT config\n",
    "        \"use_peft\": True,\n",
    "        \"lora_r\": 32,\n",
    "        \"lora_alpha\": 32,\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"lora_bias\": \"none\",\n",
    "    }\n",
    "args = SimpleNamespace(**args)  # same type as argparse would return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = []\n",
    "for i in range(args.num_envs):\n",
    "    env = gym.make(args.env_id)\n",
    "    env.seed(100 * args.seed + i)\n",
    "    envs.append(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12c3d1335d42e9abce267b6e47de83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_id, padding_side=\"left\")\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(args.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_model = create_reference_model(model, num_shared_layers=args.num_shared_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
