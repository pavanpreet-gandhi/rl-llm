{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /home/ubuntu/rl-llm\n",
      "Current directory: /home/ubuntu/rl-llm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if we're in the root directory of rl-llm repo\n",
    "if not os.path.basename(os.getcwd()) == 'rl-llm':\n",
    "    # If we're in a subdirectory of rl-llm, find the root and cd to it\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != 'rl-llm' and os.path.dirname(current_path) != current_path:\n",
    "        current_path = os.path.dirname(current_path)\n",
    "    \n",
    "    if os.path.basename(current_path) == 'rl-llm':\n",
    "        os.chdir(current_path)\n",
    "        print(f\"Changed directory to: {current_path}\")\n",
    "    else:\n",
    "        print(\"Not in rl-llm repository structure\")\n",
    "else:\n",
    "    print(\"Already in rl-llm root directory\")\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-GoTo-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Open-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Pickup-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-PutNext-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "2025-04-03 16:53:14.317232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743699194.326713   13647 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743699194.331893   13647 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from src import EnvManager, sample_batch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e571f03f50408da28120d348702d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\" # TODO: Test Llama-1B and Llama-3B (and optionally Qwen with reasoning)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "generation_kwargs = {\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 10,\n",
    "    \"top_p\": 0.95,\n",
    "    \"temperature\": 0.8,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}\n",
    "env_id = \"BabyAI-PickUpSeqGoTo-v0\" # TODO: Test GoTo, Pickup, PutNext, Open, and PickUpSeqGoTo\n",
    "env_ids = [env_id]\n",
    "context_window = 3 # TODO: Test 1, 2, 3, and 5 (if it's feasible)\n",
    "num_envs = 4 # TODO: See what is optimal for you (might vary with model, env, and device)\n",
    "envs = [\n",
    "        EnvManager(\n",
    "            env_ids, \n",
    "            invalid_action_penalty=-2,\n",
    "            consecutive_invalid_actions_allowed=5,\n",
    "        )\n",
    "        for i in range(num_envs)\n",
    "    ]\n",
    "reasoning_flag = False\n",
    "batch_size = 128\n",
    "# TODO: You may also need to play around with the system_prompt to get valid actions if testing other models such as 1B or Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/5:\n",
      "  Sample batch time: 35.79 seconds\n",
      "  Total generate time: 35.58 seconds\n",
      "  Number of episodes: 1\n",
      "Batch 2/5:\n",
      "  Sample batch time: 35.06 seconds\n",
      "  Total generate time: 34.82 seconds\n",
      "  Number of episodes: 4\n",
      "Batch 3/5:\n",
      "  Sample batch time: 37.00 seconds\n",
      "  Total generate time: 36.77 seconds\n",
      "  Number of episodes: 3\n",
      "Batch 4/5:\n",
      "  Sample batch time: 37.05 seconds\n",
      "  Total generate time: 36.82 seconds\n",
      "  Number of episodes: 4\n",
      "Batch 5/5:\n",
      "  Sample batch time: 35.63 seconds\n",
      "  Total generate time: 35.40 seconds\n",
      "  Number of episodes: 4\n"
     ]
    }
   ],
   "source": [
    "total_times = []\n",
    "total_generate_times = []\n",
    "num_episodes_per_batch = []\n",
    "successs = []\n",
    "rewardss = []\n",
    "episode_lengths = []\n",
    "num_invalid_actions = []\n",
    "\n",
    "num_batches = 5\n",
    "for i in range(num_batches):\n",
    "\n",
    "    start_time = time.time()\n",
    "    queries, responses, rewards, stats, running_stats = sample_batch(\n",
    "        envs,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        generation_kwargs,\n",
    "        device,\n",
    "        batch_size=batch_size,\n",
    "        context_window=context_window,\n",
    "        reasoning_flag = reasoning_flag,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    sample_batch_time = end_time - start_time\n",
    "\n",
    "    total_times.append(sample_batch_time)\n",
    "    total_generate_times.append(stats[\"total_generate_time\"])\n",
    "    num_episodes = len(running_stats['success'][env_id])\n",
    "    num_episodes_per_batch.append(num_episodes)\n",
    "\n",
    "    successs.extend(running_stats['success'][env_id])\n",
    "    rewardss.extend(running_stats['rewards'][env_id])\n",
    "    episode_lengths.extend(running_stats['episode_lengths'][env_id])\n",
    "    num_invalid_actions.extend(running_stats['num_invalid_actions'][env_id])\n",
    "    print(f\"Batch {i+1}/{num_batches}:\")\n",
    "    print(f\"  Sample batch time: {sample_batch_time:.2f} seconds\")\n",
    "    print(f\"  Total generate time: {stats['total_generate_time']:.2f} seconds\")\n",
    "    print(f\"  Number of episodes: {num_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:\n",
      "Model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Environment: BabyAI-PickUpSeqGoTo-v0\n",
      "Context Window: 3\n",
      "Number of environments: 4\n",
      "Reasoning: Disabled\n",
      "\n",
      "Summary of results:\n",
      "Total batches processed: 5\n",
      "Average sample batch time: 36.11 seconds\n",
      "Average total generate time: 35.88 seconds\n",
      "Number of episodes per batch ranges between: 1 to 4\n",
      "Total number of episodes: 16\n",
      "Success rate: 6.25%\n",
      "Average rewards: 0.06\n",
      "Average episode length: 120.62\n",
      "Average number of invalid actions: 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment:\")\n",
    "print(f\"Model: {model_id}\")\n",
    "print(f\"Environment: {env_id}\")\n",
    "print(f\"Context Window: {context_window}\")\n",
    "print(f\"Number of environments: {num_envs}\")\n",
    "print(f\"Reasoning: {'Enabled' if reasoning_flag else 'Disabled'}\")\n",
    "print()\n",
    "\n",
    "print(\"Summary of results:\")\n",
    "print(f\"Total batches processed: {num_batches}\")\n",
    "print(f\"Average sample batch time: {sum(total_times)/num_batches:.2f} seconds\")\n",
    "print(f\"Average total generate time: {sum(total_generate_times)/num_batches:.2f} seconds\")\n",
    "print(f\"Number of episodes per batch ranges between: {min(num_episodes_per_batch)} to {max(num_episodes_per_batch)}\")\n",
    "print(f\"Total number of episodes: {sum(num_episodes_per_batch)}\")\n",
    "print(f\"Success rate: {sum(successs) / len(successs) * 100:.2f}%\")\n",
    "print(f\"Average rewards: {sum(rewardss) / len(rewardss):.2f}\")\n",
    "print(f\"Average episode length: {sum(episode_lengths) / len(episode_lengths):.2f}\")\n",
    "print(f\"Average number of invalid actions: {sum(num_invalid_actions) / len(num_invalid_actions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: GoTo works well even with context widnow of 1\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-GoTo-v0\n",
    "Context Window: 1\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 10\n",
    "Average sample batch time: 9.77 seconds\n",
    "Average total generate time: 9.65 seconds\n",
    "Number of episodes per batch ranges between: 4 to 8\n",
    "Success rate: 74.58%\n",
    "Average rewards: 0.52\n",
    "Average episode length: 32.49\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Pickup has no success with the same settings as prev GoTo experiment\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 1\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 10\n",
    "Average sample batch time: 10.08 seconds\n",
    "Average total generate time: 9.96 seconds\n",
    "Number of episodes per batch ranges between: 4 to 4\n",
    "Success rate: 0.00%\n",
    "Average rewards: 0.00\n",
    "Average episode length: 64.00\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Changed prompt but did not seem to help\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 1\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 10\n",
    "Average sample batch time: 14.32 seconds\n",
    "Average total generate time: 14.21 seconds\n",
    "Number of episodes per batch ranges between: 2 to 4\n",
    "Success rate: 0.00%\n",
    "Average rewards: 0.00\n",
    "Average episode length: 64.00\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Success! Some sign of life with increased context window.\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 3\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 20.86 seconds\n",
    "Average total generate time: 20.75 seconds\n",
    "Number of episodes per batch ranges between: 2 to 4\n",
    "Success rate: 13.33%\n",
    "Average rewards: 0.11\n",
    "Average episode length: 57.13\n",
    "Average number of invalid actions: 1.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The old prompt works even better!\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 3\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 17.13 seconds\n",
    "Average total generate time: 17.01 seconds\n",
    "Number of episodes per batch ranges between: 3 to 4\n",
    "Success rate: 42.11%\n",
    "Average rewards: 0.30\n",
    "Average episode length: 45.42\n",
    "Average number of invalid actions: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Further increasing context window to 5 yielded slightly better results.\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 5\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 23.26 seconds\n",
    "Average total generate time: 23.13 seconds\n",
    "Number of episodes per batch ranges between: 3 to 6\n",
    "Total number of episodes: 22\n",
    "Success rate: 45.45%\n",
    "Average rewards: 0.31\n",
    "Average episode length: 41.55\n",
    "Average number of invalid actions: 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Sanity check with context window back to 3 see that results are reasonably reporoducible.\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 3\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 17.33 seconds\n",
    "Average total generate time: 17.21 seconds\n",
    "Number of episodes per batch ranges between: 3 to 7\n",
    "Total number of episodes: 22\n",
    "Success rate: 40.91%\n",
    "Average rewards: 0.31\n",
    "Average episode length: 44.68\n",
    "Average number of invalid actions: 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Even context size of 2 seems to be sufficient for Pickup (with much faster sample batch time)\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 2\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 13.91 seconds\n",
    "Average total generate time: 13.79 seconds\n",
    "Number of episodes per batch ranges between: 2 to 5\n",
    "Total number of episodes: 18\n",
    "Success rate: 38.89%\n",
    "Average rewards: 0.20\n",
    "Average episode length: 52.67\n",
    "Average number of invalid actions: 0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Just confirming that context size 1 defineitely does not work for Pickup\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Pickup-v0\n",
    "Context Window: 1\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 9.92 seconds\n",
    "Average total generate time: 9.80 seconds\n",
    "Number of episodes per batch ranges between: 4 to 4\n",
    "Total number of episodes: 20\n",
    "Success rate: 0.00%\n",
    "Average rewards: 0.00\n",
    "Average episode length: 64.00\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: PutNext also does not work for context window of 1\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-PutNext-v0\n",
    "Context Window: 1\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 21.00 seconds\n",
    "Average total generate time: 20.76 seconds\n",
    "Number of episodes per batch ranges between: 3 to 4\n",
    "Total number of episodes: 19\n",
    "Success rate: 0.00%\n",
    "Average rewards: 0.00\n",
    "Average episode length: 128.00\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Even context window of 2 does not work for PutNext\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-PutNext-v0\n",
    "Context Window: 2\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 28.63 seconds\n",
    "Average total generate time: 28.39 seconds\n",
    "Number of episodes per batch ranges between: 1 to 3\n",
    "Total number of episodes: 11\n",
    "Success rate: 0.00%\n",
    "Average rewards: 0.00\n",
    "Average episode length: 128.00\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Decent success with context window of 5 on PutNext (at the expense of longer sample batch time)\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-PutNext-v0\n",
    "Context Window: 5\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 48.36 seconds\n",
    "Average total generate time: 48.13 seconds\n",
    "Number of episodes per batch ranges between: 1 to 3\n",
    "Total number of episodes: 11\n",
    "Success rate: 18.18%\n",
    "Average rewards: 0.08\n",
    "Average episode length: 119.09\n",
    "Average number of invalid actions: 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Small success with context window of 3 on PutNext, but not as good as 5\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-PutNext-v0\n",
    "Context Window: 3\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 35.11 seconds\n",
    "Average total generate time: 34.88 seconds\n",
    "Number of episodes per batch ranges between: 1 to 4\n",
    "Total number of episodes: 13\n",
    "Success rate: 7.69%\n",
    "Average rewards: 0.04\n",
    "Average episode length: 123.85\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Even Open works with context window of 5!\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Open-v0\n",
    "Context Window: 5\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 39.76 seconds\n",
    "Average total generate time: 39.57 seconds\n",
    "Number of episodes per batch ranges between: 2 to 2\n",
    "Total number of episodes: 10\n",
    "Success rate: 10.00%\n",
    "Average rewards: 0.06\n",
    "Average episode length: 88.20\n",
    "Average number of invalid actions: 3.40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Prev 10% success rate might have been a fluke, since there was no success in 3 more batches\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Open-v0\n",
    "Context Window: 5\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 3\n",
    "Average sample batch time: 37.97 seconds\n",
    "Average total generate time: 37.78 seconds\n",
    "Number of episodes per batch ranges between: 2 to 4\n",
    "Total number of episodes: 9\n",
    "Success rate: 0.00%\n",
    "Average rewards: 0.00\n",
    "Average episode length: 82.11\n",
    "Average number of invalid actions: 3.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Maybe not, since there is a non-zero success rate even with context window of 3\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-Open-v0\n",
    "Context Window: 3\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 35.46 seconds\n",
    "Average total generate time: 35.23 seconds\n",
    "Number of episodes per batch ranges between: 2 to 3\n",
    "Total number of episodes: 12\n",
    "Success rate: 8.33%\n",
    "Average rewards: 0.04\n",
    "Average episode length: 123.25\n",
    "Average number of invalid actions: 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Context window of 5 is sufficient for PickUpSeqGoTo too!\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-PickUpSeqGoTo-v0\n",
    "Context Window: 5\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 47.41 seconds\n",
    "Average total generate time: 47.18 seconds\n",
    "Number of episodes per batch ranges between: 2 to 4\n",
    "Total number of episodes: 13\n",
    "Success rate: 38.46%\n",
    "Average rewards: 0.18\n",
    "Average episode length: 108.23\n",
    "Average number of invalid actions: 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Small success rate with context window of 3, but not as good as 5 for PickUpSeqGoTo\n",
    "```Experiment:\n",
    "Model: meta-llama/Llama-3.2-3B-Instruct\n",
    "Environment: BabyAI-PickUpSeqGoTo-v0\n",
    "Context Window: 3\n",
    "Number of environments: 4\n",
    "Reasoning: Disabled\n",
    "\n",
    "Summary of results:\n",
    "Total batches processed: 5\n",
    "Average sample batch time: 36.11 seconds\n",
    "Average total generate time: 35.88 seconds\n",
    "Number of episodes per batch ranges between: 1 to 4\n",
    "Total number of episodes: 16\n",
    "Success rate: 6.25%\n",
    "Average rewards: 0.06\n",
    "Average episode length: 120.62\n",
    "Average number of invalid actions: 0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- [ ] Compare with other models\n",
    "- [ ] Compare reasoning with non-reasoning\n",
    "- [ ] Vary the number of distractors\n",
    "- [ ] Figure out the optimal setting of num_envs for time efficiency\n",
    "\n",
    "NOTE: We can try GoTo, and PickUpSeqGoTo to get a sense for these other experiments?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
