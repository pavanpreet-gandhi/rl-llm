{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /workspace/rl-llm\n",
      "Current directory: /workspace/rl-llm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if we're in the root directory of rl-llm repo\n",
    "if not os.path.basename(os.getcwd()) == 'rl-llm':\n",
    "    # If we're in a subdirectory of rl-llm, find the root and cd to it\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != 'rl-llm' and os.path.dirname(current_path) != current_path:\n",
    "        current_path = os.path.dirname(current_path)\n",
    "    \n",
    "    if os.path.basename(current_path) == 'rl-llm':\n",
    "        os.chdir(current_path)\n",
    "        print(f\"Changed directory to: {current_path}\")\n",
    "    else:\n",
    "        print(\"Not in rl-llm repository structure\")\n",
    "else:\n",
    "    print(\"Already in rl-llm root directory\")\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-GoTo-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Open-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Pickup-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-PutNext-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from src import EnvManager, sample_episodes\n",
    "from transformers import AutoTokenizer\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from peft import PeftConfig\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Suppress spammy logs from transformers, \n",
    "# e.g. \"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\"\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_peft_and_vhead(model_id, revision=None):\n",
    "    \"\"\"\n",
    "    Load a model with both PEFT adapters and value head\n",
    "    \n",
    "    Args:\n",
    "        model_id: Path to model or HF hub model ID\n",
    "        device: Device to load the model to\n",
    "        revision: Specific model revision/commit hash to load\n",
    "    \n",
    "    Returns:\n",
    "        model: The loaded model with adapters and value head\n",
    "        tokenizer: The associated tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get PEFT config to find base model\n",
    "    peft_config = PeftConfig.from_pretrained(model_id, revision=revision)\n",
    "    base_model_id = peft_config.base_model_name_or_path\n",
    "    \n",
    "    print(f\"Base model: {base_model_id}\")\n",
    "    print(f\"Loading with PEFT adapters from: {model_id}\")\n",
    "    if revision:\n",
    "        print(f\"Using revision: {revision}\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_id, padding_side='left')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model with value head from the base model\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        base_model_id,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # Now load the PEFT adapter weights\n",
    "    model = model.from_pretrained(model_id, device_map=\"auto\", revision=revision)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_base_model_with_vhead(model_id):\n",
    "    \"\"\"\n",
    "    Load a base model with value head\n",
    "    \n",
    "    Args:\n",
    "        model_id: Path to model or HF hub model ID\n",
    "    \n",
    "    Returns:\n",
    "        model: The loaded model with value head\n",
    "        tokenizer: The associated tokenizer\n",
    "    \"\"\"\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    print(f\"Loading base model with value head from: {model_id}\")\n",
    "    \n",
    "    # Initialize model with value head\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify models to be evaluated\n",
    "model_configs = {\n",
    "    \"Baseline\": {\n",
    "        \"load_fn\": load_base_model_with_vhead,\n",
    "        \"model_id\": \"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "        \"reasoning_flag\": None\n",
    "    },\n",
    "    \"Trial2r\": {\n",
    "        \"load_fn\": load_model_with_peft_and_vhead,\n",
    "        \"model_id\": \"CatkinChen/final_runs-Reasoning_trial_2_dist_0\",\n",
    "        \"revision\": None,   # Optionally set a revision if needed\n",
    "        \"reasoning_flag\": True\n",
    "    },\n",
    "    \"Trial2\": {\n",
    "        \"load_fn\": load_model_with_peft_and_vhead,\n",
    "        \"model_id\": \"CatkinChen/final_runs-No_Reasoning__trial_2\",\n",
    "        \"revision\": None,   # Optionally set a revision if needed\n",
    "        \"reasoning_flag\": False\n",
    "    },\n",
    "    \"Trial1\": {\n",
    "        \"load_fn\": load_model_with_peft_and_vhead,\n",
    "        \"model_id\": \"Heisenger/final_runs-No_Reasoning_trial_1_dist_0\",\n",
    "        \"revision\": None,   # Optionally set a revision if needed\n",
    "        \"reasoning_flag\": False\n",
    "    },\n",
    "    \"Trial1r\": {\n",
    "        \"load_fn\": load_model_with_peft_and_vhead,\n",
    "        \"model_id\": \"Heisenger/final_runs-Reasoning__trial_1\",\n",
    "        \"revision\": None,   # Optionally set a revision if needed\n",
    "        \"reasoning_flag\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and testing model: Baseline\n",
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fc6eaf45e54deb9a51efba66e64419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key and go to the door with the lock that corresponds to your name, unlock it, and enter. Sounds simple enough, but there is a catch. The key is labeled \"C\". The door you need to unlock is labeled \"A\". Now,\n",
      "\n",
      "Loading and testing model: Trial2r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb0b4649d0244ca98bc33da2261151e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-Reasoning_trial_2_dist_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2179d68c63645509d2aa667443eb184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517f7ecf0a1a449295ddaf656204378f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269e8eaa12a74b26a05d701b867f227a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be87852dece4902ae0dd01feb1cd5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key. When you pick up the key, a new item is added to the room. The item is a small wooden box. The key is now useless, but the wooden box has a keyhole in it. You need to use the key to unlock\n",
      "\n",
      "Loading and testing model: Trial2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2de8e2993944a5bb5bd330deb90f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-No_Reasoning__trial_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbdc4dcd5614a3bb8364c8db7ada2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db76a99e367148d9bdd011c46c82bc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425db29772d245f8917eed64e791353d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3c08df4d124d3ba96f2c81d3228bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key and put it in the lock.\n",
      "\n",
      "It seems counterintuitive but I am to open the door, turn the handle, walk out the door, and then look at the door. The final instruction is to put the key in the keyhole. It\n",
      "\n",
      "Loading and testing model: Trial1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffa5119ae91456187d6d91285d4aab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: Heisenger/final_runs-No_Reasoning_trial_1_dist_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc68cd74e7414ba7b5981626236e6e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2812ead0d30c46938164b1d1c3ff7fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac40c605454a4493ada57a62afa8bd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae7ecc3e9e943888e66beaef693459f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key, open the door, and walk out. The door is locked, but you have the key. You walk over to the door, insert the key into the keyhole and turn it. The door is now unlocked. You push the door open and\n",
      "\n",
      "Loading and testing model: Trial1r\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: Heisenger/final_runs-Reasoning__trial_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a5dbf024b43ffb0bd8eb88ee3a896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bea77f8fbab47b69c35ac738df30dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key and take it with you when you leave the room. However, there is a condition: you can only take the key if you answer a question correctly. The question is: what is the only thing that is not moving in this room?\n",
      "\n",
      "The answer\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Iterate over each model configuration to load and test with a simple query\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\nLoading and testing model: {model_name}\")\n",
    "\n",
    "    # Retrieve the loading function, model id, and optionally, the commit hash\n",
    "    load_fn = config[\"load_fn\"]\n",
    "    model_id = config[\"model_id\"]\n",
    "    revision = config.get(\"revision\", None)\n",
    "\n",
    "    # Load the model and associated tokenizer using the specified function\n",
    "    if load_fn.__name__ == \"load_base_model_with_vhead\":\n",
    "        model, tokenizer = load_fn(model_id)\n",
    "    else:\n",
    "        model, tokenizer = load_fn(model_id, revision)\n",
    "\n",
    "    # Simple query to test the model\n",
    "    prompt = \"You are in a room with a key. The instruction is to: pick up the key\"\n",
    "    \n",
    "    # Tokenize the input prompt and send tensors to device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate output with your text-generation settings\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50, do_sample=True, temperature=0.7)\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Display the model's output\n",
    "    print(\"Model output:\")\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters for text generation\n",
    "generation_kwargs = {\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.7,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}\n",
    "\n",
    "# Define the seen and unseen environments\n",
    "seen_env_ids = [\"BabyAI-GoTo-v0\", \"BabyAI-Pickup-v0\"]\n",
    "unseen_env_ids = [\"BabyAI-PutNext-v0\"] #\"BabyAI-Open-v0\", \"BabyAI-PickUpSeqGoTo-v0\"\n",
    "\n",
    "# Reasoning flags list\n",
    "reasoning_flag = config[\"reasoning_flag\"]\n",
    "reasoning_flags = [True, False] if reasoning_flag is None else [reasoning_flag]\n",
    "\n",
    "# Number of parallel environments to instantiate for each configuration.\n",
    "num_envs = 6\n",
    "\n",
    "# Initialise a container for the aggregated results.\n",
    "evaluation_results = {}\n",
    "\n",
    "# Function that evaluates a model on a given environment and reasoning flag\n",
    "def evaluate_model_on_envs(env_id, reasoning_flag, model, tokenizer, generation_kwargs, device, num_episodes=50):\n",
    "    # Create environment managers for the current env_id and reasoning flag.\n",
    "    env_managers = [\n",
    "        EnvManager(\n",
    "            env_ids=[env_id],\n",
    "            invalid_action_penalty=-1,\n",
    "            consecutive_invalid_actions_allowed=5,\n",
    "            reasoning_flag=reasoning_flag,\n",
    "            num_dists=0,\n",
    "        )\n",
    "        for _ in range(num_envs)\n",
    "    ]\n",
    "    \n",
    "    # Run episodes using sample_episodes\n",
    "    stats, contexts = sample_episodes(\n",
    "        envs=env_managers,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        generation_kwargs=generation_kwargs,\n",
    "        device=device,\n",
    "        number_of_episodes=num_episodes,\n",
    "        context_window=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "    )\n",
    "    \n",
    "    # Calculate the summary metrics.\n",
    "    success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "    avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "    std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "    avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "    std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "    avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "    \n",
    "    # Bundle the results into a dictionary.\n",
    "    results = {\n",
    "        \"success_rate\": success_rate,\n",
    "        \"avg_reward\": avg_reward,\n",
    "        \"std_reward\": std_reward,\n",
    "        \"avg_episode_length\": avg_episode_length,\n",
    "        \"std_episode_length\": std_episode_length,\n",
    "        \"avg_num_invalid_actions\": avg_num_invalid_actions,\n",
    "        \"contexts\": contexts,  # optional: include detailed contexts if needed\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Baseline\n",
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a70892e36d4728a01b2dfbbe94e492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Baseline on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Baseline on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Baseline on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Baseline on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Baseline on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Loading model: Trial2r\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-Reasoning_trial_2_dist_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd66d2414fd94e43bd575213153e2c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dd8295985545c1a392d2089fceaca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Trial2r on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "Evaluating Trial2r on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "Evaluating Trial2r on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial2r on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial2r on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial2r on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \n",
      "Loading model: Trial2\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-No_Reasoning__trial_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714a7d7b19bc454c8163e471731fb9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dd30dbe8dc4f59bbd7c966cabc86e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Trial2 on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "Evaluating Trial2 on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial2 on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial2 on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial2 on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "Evaluating Trial2 on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Loading model: Trial1\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: Heisenger/final_runs-No_Reasoning_trial_1_dist_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65ac69624fb47b9a4dd758f562ae277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6619f7d4cf485390777b4dd2df8264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Trial1 on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "Evaluating Trial1 on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1 on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1 on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1 on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1 on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Loading model: Trial1r\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: Heisenger/final_runs-Reasoning__trial_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb49b6f0463a434884e6f31dc3b4e197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6982f71bb1804188ae48b00a13b90b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Trial1r on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1r on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1r on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1r on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "Evaluating Trial1r on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \n",
      "Evaluating Trial1r on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
      "\n",
      "Results for Baseline on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 0.65\n",
      "  Avg Reward: 0.5276562499999999 (Std: 0.40758606791496277)\n",
      "  Avg Episode Length: 11.8 (Std: 8.15378475189209)\n",
      "  Avg Num. of Invalid Actions: 2.05\n",
      "\n",
      "Results for Baseline on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 0.95\n",
      "  Avg Reward: 0.719375 (Std: 0.25085964798927307)\n",
      "  Avg Episode Length: 21.9 (Std: 18.948406219482422)\n",
      "  Avg Num. of Invalid Actions: 2.3\n",
      "\n",
      "Results for Baseline on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.65\n",
      "  Avg Reward: 0.4657812499999999 (Std: 0.37496262788772583)\n",
      "  Avg Episode Length: 16.85 (Std: 11.531536102294922)\n",
      "  Avg Num. of Invalid Actions: 2.9\n",
      "\n",
      "Results for Baseline on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 0.9\n",
      "  Avg Reward: 0.5871093749999998 (Std: 0.316510409116745)\n",
      "  Avg Episode Length: 29.8 (Std: 22.437280654907227)\n",
      "  Avg Num. of Invalid Actions: 1.15\n",
      "\n",
      "Results for Baseline on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.05\n",
      "  Avg Reward: 0.02890625 (Std: 0.1292726844549179)\n",
      "  Avg Episode Length: 35.25 (Std: 49.651283264160156)\n",
      "  Avg Num. of Invalid Actions: 4.1\n",
      "\n",
      "Results for Baseline on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.1\n",
      "  Avg Reward: 0.030742187499999997 (Std: 0.09615683555603027)\n",
      "  Avg Episode Length: 121.45 (Std: 22.60525131225586)\n",
      "  Avg Num. of Invalid Actions: 3.95\n",
      "\n",
      "Results for Trial2r on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.878125 (Std: 0.09867160022258759)\n",
      "  Avg Episode Length: 8.714285714285714 (Std: 7.0366387367248535)\n",
      "  Avg Num. of Invalid Actions: 0.047619047619047616\n",
      "\n",
      "Results for Trial2r on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.9149553571428571 (Std: 0.056333646178245544)\n",
      "  Avg Episode Length: 6.0476190476190474 (Std: 4.005948066711426)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial2r on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.7\n",
      "  Avg Reward: 0.5425000000000001 (Std: 0.4035199284553528)\n",
      "  Avg Episode Length: 30.4 (Std: 25.715856552124023)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial2r on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.8692187499999999 (Std: 0.06486103683710098)\n",
      "  Avg Episode Length: 9.3 (Std: 4.612340450286865)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial2r on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 119.0 (Std: 29.237682342529297)\n",
      "  Avg Num. of Invalid Actions: 2.2\n",
      "\n",
      "Results for Trial2r on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 128.0 (Std: 0.0)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial2 on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 0.23809523809523808\n",
      "  Avg Reward: 0.2193452380952381 (Std: 0.40252360701560974)\n",
      "  Avg Episode Length: 5.380952380952381 (Std: 1.4654756784439087)\n",
      "  Avg Num. of Invalid Actions: 4.0\n",
      "\n",
      "Results for Trial2 on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.92546875 (Std: 0.032932113856077194)\n",
      "  Avg Episode Length: 5.3 (Std: 2.341839075088501)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial2 on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.15\n",
      "  Avg Reward: 0.138046875 (Std: 0.3372262418270111)\n",
      "  Avg Episode Length: 5.8 (Std: 1.9358121156692505)\n",
      "  Avg Num. of Invalid Actions: 4.7\n",
      "\n",
      "Results for Trial2 on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.9036718749999999 (Std: 0.04982823505997658)\n",
      "  Avg Episode Length: 7.2 (Std: 4.2624430656433105)\n",
      "  Avg Num. of Invalid Actions: 0.35\n",
      "\n",
      "Results for Trial2 on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 7.190476190476191 (Std: 5.37232780456543)\n",
      "  Avg Num. of Invalid Actions: 5.857142857142857\n",
      "\n",
      "Results for Trial2 on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 144.65 (Std: 48.87284851074219)\n",
      "  Avg Num. of Invalid Actions: 26.7\n",
      "\n",
      "Results for Trial1 on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 0.6666666666666666\n",
      "  Avg Reward: 0.6224702380952382 (Std: 0.45168912410736084)\n",
      "  Avg Episode Length: 5.809523809523809 (Std: 2.4003968238830566)\n",
      "  Avg Num. of Invalid Actions: 2.142857142857143\n",
      "\n",
      "Results for Trial1 on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.93390625 (Std: 0.03164268285036087)\n",
      "  Avg Episode Length: 4.7 (Std: 2.2501461505889893)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial1 on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.85\n",
      "  Avg Reward: 0.7382031249999998 (Std: 0.3254707455635071)\n",
      "  Avg Episode Length: 9.8 (Std: 5.8991522789001465)\n",
      "  Avg Num. of Invalid Actions: 1.4\n",
      "\n",
      "Results for Trial1 on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.9149218749999999 (Std: 0.025596681982278824)\n",
      "  Avg Episode Length: 6.05 (Std: 1.820208191871643)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial1 on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.05\n",
      "  Avg Reward: 0.0433203125 (Std: 0.1937343329191208)\n",
      "  Avg Episode Length: 16.15 (Std: 11.833382606506348)\n",
      "  Avg Num. of Invalid Actions: 7.5\n",
      "\n",
      "Results for Trial1 on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.75\n",
      "  Avg Reward: 0.6466406250000001 (Std: 0.39141491055488586)\n",
      "  Avg Episode Length: 46.9 (Std: 49.647071838378906)\n",
      "  Avg Num. of Invalid Actions: 0.2\n",
      "\n",
      "Results for Trial1r on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 1.0\n",
      "  Avg Reward: 0.8214062499999997 (Std: 0.0987120270729065)\n",
      "  Avg Episode Length: 12.7 (Std: 7.019521713256836)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial1r on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 0.8\n",
      "  Avg Reward: 0.591875 (Std: 0.3625572621822357)\n",
      "  Avg Episode Length: 27.65 (Std: 23.353744506835938)\n",
      "  Avg Num. of Invalid Actions: 0.05\n",
      "\n",
      "Results for Trial1r on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 58.75 (Std: 16.92047882080078)\n",
      "  Avg Num. of Invalid Actions: 0.8\n",
      "\n",
      "Results for Trial1r on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 0.15\n",
      "  Avg Reward: 0.067734375 (Std: 0.20259056985378265)\n",
      "  Avg Episode Length: 61.2 (Std: 13.363737106323242)\n",
      "  Avg Num. of Invalid Actions: 0.95\n",
      "\n",
      "Results for Trial1r on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 128.0 (Std: 0.0)\n",
      "  Avg Num. of Invalid Actions: 0.0\n",
      "\n",
      "Results for Trial1r on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 128.1 (Std: 0.3077934980392456)\n",
      "  Avg Num. of Invalid Actions: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Main Evaluation Loop\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    # Load model and tokenizer via the appropriate function.\n",
    "    load_fn = config[\"load_fn\"]\n",
    "    model_id = config[\"model_id\"]\n",
    "    \n",
    "    # Load the model using the appropriate function and arguments\n",
    "    if load_fn.__name__ == \"load_base_model_with_vhead\":\n",
    "        model, tokenizer = load_fn(model_id)\n",
    "    else:\n",
    "        revision = config.get(\"revision\")\n",
    "        model, tokenizer = load_fn(model_id, revision)\n",
    "    \n",
    "    # Update generation kwargs for this model. (Make sure you use its pad_token_id.)\n",
    "    local_generation_kwargs = {\n",
    "        \"max_new_tokens\": 20,\n",
    "        \"do_sample\": True,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.7,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    }\n",
    "    \n",
    "    # Loop over environments (seen and unseen) and reasoning flags.\n",
    "    # You can separate these groups as needed.\n",
    "    for env_group_name, env_ids in zip([\"Seen\", \"Unseen\"], [seen_env_ids, unseen_env_ids]):\n",
    "        for env_id in env_ids:\n",
    "            for reasoning in reasoning_flags:\n",
    "                print(f\"Evaluating {model_name} on {env_group_name} env: {env_id} with reasoning={reasoning}\")\n",
    "                results = evaluate_model_on_envs(\n",
    "                    env_id=env_id,\n",
    "                    reasoning_flag=reasoning,\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    generation_kwargs=local_generation_kwargs,\n",
    "                    device=device,\n",
    "                    num_episodes=20  # Adjust as needed.\n",
    "                )\n",
    "                # Save results with a composite key.\n",
    "                evaluation_results[(model_name, env_id, reasoning)] = results\n",
    "\n",
    "# --- Reporting the results ---\n",
    "for key, result in evaluation_results.items():\n",
    "    model_name, env_id, reasoning = key\n",
    "    print(f\"\\nResults for {model_name} on {env_id} (reasoning={reasoning}):\")\n",
    "    print(f\"  Success Rate: {result['success_rate']}\")\n",
    "    print(f\"  Avg Reward: {result['avg_reward']} (Std: {result['std_reward']})\")\n",
    "    print(f\"  Avg Episode Length: {result['avg_episode_length']} (Std: {result['std_episode_length']})\")\n",
    "    print(f\"  Avg Num. of Invalid Actions: {result['avg_num_invalid_actions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_success_rates(env_ids, model_configs_to_plot, evaluation_results, title):\n",
    "    \"\"\"\n",
    "    Plot bar chart of success rates for specified model configurations across environments.\n",
    "    \n",
    "    Args:\n",
    "        env_ids (list): List of environment IDs to plot.\n",
    "        model_configs_to_plot (list): List of tuples (model_name, reasoning) to include.\n",
    "        evaluation_results (dict): Dictionary containing evaluation metrics.\n",
    "        title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    n_envs = len(env_ids)\n",
    "    n_models = len(model_configs_to_plot)\n",
    "    bar_width = 0.8 / n_models  # Adjust bar width based on number of models\n",
    "    index = np.arange(n_envs)   # Positions for environment groups\n",
    "    \n",
    "    for i, (model_name, reasoning) in enumerate(model_configs_to_plot):\n",
    "        # Extract success rates for this model configuration\n",
    "        success_rates = []\n",
    "        for env in env_ids:\n",
    "            key = (model_name, env, reasoning)\n",
    "            if key in evaluation_results:\n",
    "                success_rates.append(evaluation_results[key][\"success_rate\"])\n",
    "            else:\n",
    "                success_rates.append(0)  # Default to 0 if data is missing\n",
    "        \n",
    "        # Plot bars for this model\n",
    "        label = f\"{model_name} {'R' if reasoning else 'NR'}\"\n",
    "        ax.bar(index + i * bar_width, success_rates, bar_width, label=label)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(\"Environments\", fontsize=12)\n",
    "    ax.set_ylabel(\"Success Rate\", fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xticks(index + bar_width * (n_models - 1) / 2)\n",
    "    ax.set_xticklabels(env_ids, rotation=45, ha='right')\n",
    "    ax.set_ylim(0, 1)  # Success rate ranges from 0 to 1\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define all environments to plot\n",
    "env_ids = seen_env_ids + unseen_env_ids\n",
    "\n",
    "# First plot: Baseline (R), Baseline (NR), Trial1 (NR), Trial1r (R)\n",
    "first_plot_models = [\n",
    "    (\"Baseline\", True),   # Baseline with reasoning\n",
    "    (\"Baseline\", False),  # Baseline without reasoning\n",
    "    (\"Trial1\", False),    # Trial1 without reasoning\n",
    "    (\"Trial1r\", True)     # Trial1r with reasoning\n",
    "]\n",
    "plot_success_rates(\n",
    "    env_ids=env_ids,\n",
    "    model_configs_to_plot=first_plot_models,\n",
    "    evaluation_results=evaluation_results,\n",
    "    title=\"Success Rate Comparison: Baseline and Trial1 Models\"\n",
    ")\n",
    "\n",
    "# Second plot: Baseline (R), Baseline (NR), Trial2 (NR), Trial2r (R)\n",
    "second_plot_models = [\n",
    "    (\"Baseline\", True),   # Baseline with reasoning\n",
    "    (\"Baseline\", False),  # Baseline without reasoning\n",
    "    (\"Trial2\", False),    # Trial2 without reasoning\n",
    "    (\"Trial2r\", True)     # Trial2r with reasoning\n",
    "]\n",
    "plot_success_rates(\n",
    "    env_ids=env_ids,\n",
    "    model_configs_to_plot=second_plot_models,\n",
    "    evaluation_results=evaluation_results,\n",
    "    title=\"Success Rate Comparison: Baseline and Trial2 Models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"BabyAI-PickupTest-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CatkinChen/final_runs-No_Reasoning_trial_2_dist_3\"\n",
    "revision = None # \"cf75726c11f5b5867107f56efc8f55439635f1c6\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer = load_model_with_peft_and_vhead(model_id, revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"BabyAI-PickupTest-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning Train: Average Reward: 0.81 ± 0.26\n",
    "# Reasoning Test: Average Reward: 0.76 ± 0.32\n",
    "# Non-Reasoning Train: Average Reward: 0.74 ± 0.33\n",
    "# Non-Reasoning Test: Average Reward: 0.70 ± 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: BabyAI-Pickup-v0 with Reasoning (base model)\n",
    "# Sample size: 10\n",
    "# Success Rate: 0.50\n",
    "# Average Reward: 0.37 ± 0.40\n",
    "# Average Episode Length: 14.00 ± 9.76\n",
    "# Average Number of Invalid Actions: 3.60\n",
    "\n",
    "# Summary: BabyAI-Pickup-v0 with Reasoning (finetuned model but not run until convergence)\n",
    "# Sample size: 10\n",
    "# Success Rate: 0.70\n",
    "# Average Reward: 0.56 ± 0.41\n",
    "# Average Episode Length: 15.10 ± 10.79\n",
    "# Average Number of Invalid Actions: 2.50\n",
    "\n",
    "# Summary: BabyAI-Pickup-v0 with Reasoning (finetuned for longer)\n",
    "# Sample size: 12\n",
    "# Success Rate: 0.92\n",
    "# Average Reward: 0.80 ± 0.26\n",
    "# Average Episode Length: 9.33 ± 4.29\n",
    "# Average Number of Invalid Actions: 0.50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
