{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /workspace/rl-llm\n",
      "Current directory: /workspace/rl-llm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if we're in the root directory of rl-llm repo\n",
    "if not os.path.basename(os.getcwd()) == 'rl-llm':\n",
    "    # If we're in a subdirectory of rl-llm, find the root and cd to it\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != 'rl-llm' and os.path.dirname(current_path) != current_path:\n",
    "        current_path = os.path.dirname(current_path)\n",
    "    \n",
    "    if os.path.basename(current_path) == 'rl-llm':\n",
    "        os.chdir(current_path)\n",
    "        print(f\"Changed directory to: {current_path}\")\n",
    "    else:\n",
    "        print(\"Not in rl-llm repository structure\")\n",
    "else:\n",
    "    print(\"Already in rl-llm root directory\")\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.10/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.10/site-packages (from seaborn) (1.23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-GoTo-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Open-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Pickup-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-PutNext-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from src import EnvManager, sample_episodes\n",
    "from transformers import AutoTokenizer\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from peft import PeftConfig\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Suppress spammy logs from transformers, \n",
    "# e.g. \"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\"\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_peft_and_vhead(model_id, revision=None):\n",
    "    \"\"\"\n",
    "    Load a model with both PEFT adapters and value head\n",
    "    \n",
    "    Args:\n",
    "        model_id: Path to model or HF hub model ID\n",
    "        device: Device to load the model to\n",
    "        revision: Specific model revision/commit hash to load\n",
    "    \n",
    "    Returns:\n",
    "        model: The loaded model with adapters and value head\n",
    "        tokenizer: The associated tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get PEFT config to find base model\n",
    "    peft_config = PeftConfig.from_pretrained(model_id, revision=revision)\n",
    "    base_model_id = peft_config.base_model_name_or_path\n",
    "    \n",
    "    print(f\"Base model: {base_model_id}\")\n",
    "    print(f\"Loading with PEFT adapters from: {model_id}\")\n",
    "    if revision:\n",
    "        print(f\"Using revision: {revision}\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_id, padding_side='left')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model with value head from the base model\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        base_model_id,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # Now load the PEFT adapter weights\n",
    "    model = model.from_pretrained(model_id, device_map=\"auto\", revision=revision)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_base_model_with_vhead(model_id):\n",
    "    \"\"\"\n",
    "    Load a base model with value head\n",
    "    \n",
    "    Args:\n",
    "        model_id: Path to model or HF hub model ID\n",
    "    \n",
    "    Returns:\n",
    "        model: The loaded model with value head\n",
    "        tokenizer: The associated tokenizer\n",
    "    \"\"\"\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    print(f\"Loading base model with value head from: {model_id}\")\n",
    "    \n",
    "    # Initialize model with value head\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def plot_performance_from_results(\n",
    "    env_ids: List[str],\n",
    "    evaluation_results: Dict[Tuple[str, str, bool], Dict[str, float]],\n",
    "    metric: str,  # e.g., \"success_rate\", \"avg_reward\", etc.\n",
    "    context_window: int,\n",
    "    env_type: str,\n",
    "    checkpoint_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a bar chart comparing the performance of different model configurations.\n",
    "    \n",
    "    Parameters:\n",
    "      env_ids : List of environment IDs to plot.\n",
    "      evaluation_results : Dictionary keyed by (model_name, env_id, reasoning_flag) containing performance metrics.\n",
    "      metric : The key of the performance metric to plot (e.g., \"success_rate\").\n",
    "      context_window : Context window size (for display purposes).\n",
    "      env_type : A string describing the type of environments (e.g. \"Seen\" or \"Unseen\").\n",
    "      checkpoint_name : Name of the checkpoint/model for display.\n",
    "    \"\"\"\n",
    "    # Build dictionaries for each group:\n",
    "    baseline_non_reasoning_results = {\n",
    "        env: evaluation_results[(\"Baseline\", env, False)][metric] for env in env_ids\n",
    "    }\n",
    "    baseline_reasoning_results = {\n",
    "        env: evaluation_results[(\"Baseline\", env, True)][metric] for env in env_ids\n",
    "    }\n",
    "    # For the trained model, we follow the same convention\n",
    "    trained_reasoning_results = {\n",
    "        env: evaluation_results[(\"Trained\", env, True)][metric] for env in env_ids\n",
    "    }\n",
    "    trained_non_reasoning_results = {\n",
    "        env: evaluation_results[(\"Trained\", env, False)][metric] for env in env_ids\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    n_envs = len(env_ids)\n",
    "    bar_width = 0.2\n",
    "    index = np.arange(n_envs)\n",
    "\n",
    "    ax.bar(index - bar_width * 1.5, [baseline_non_reasoning_results[env] for env in env_ids],\n",
    "           bar_width, label=\"Baseline (Non-Reasoning)\", color='red', alpha=0.7)\n",
    "    ax.bar(index - bar_width * 0.5, [baseline_reasoning_results[env] for env in env_ids],\n",
    "           bar_width, label=\"Baseline (Reasoning)\", color='orange', alpha=0.7)\n",
    "    ax.bar(index + bar_width * 0.5, [trained_reasoning_results[env] for env in env_ids],\n",
    "           bar_width, label=\"Reasoning (Trained)\", color='blue', alpha=0.7)\n",
    "    ax.bar(index + bar_width * 1.5, [trained_non_reasoning_results[env] for env in env_ids],\n",
    "           bar_width, label=\"Non-Reasoning (Trained)\", color='green', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel(\"Environments\", fontsize=12)\n",
    "    ax.set_ylabel(metric.replace('_',' ').title(), fontsize=12)\n",
    "    ax.set_title(f\"Model Performance Comparison\\n(Checkpoint: {checkpoint_name}, Context Window: {context_window}, {env_type})\",\n",
    "                 fontsize=14)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(env_ids, rotation=45, ha='right')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify models to be evaluated\n",
    "model_configs = {\n",
    "    \"Baseline\": {\n",
    "        \"load_fn\": load_base_model_with_vhead,\n",
    "        \"model_id\": \"meta-llama/Llama-3.2-3B-Instruct\", \n",
    "    },\n",
    "    \"Trained\": {\n",
    "        \"load_fn\": load_model_with_peft_and_vhead,\n",
    "        \"model_id\": \"CatkinChen/final_runs-Reasoning_trial_2_dist_3\",   # Replace with the actual Hugging Face ID or local path.\n",
    "        \"revision\": None   # Optionally set a revision if needed.\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and testing model: Baseline\n",
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3903f100f1459087a2a8c1241b1461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key and turn it clockwise to unlock the door.\n",
      "\n",
      "## Step 1: Observe the key and the door\n",
      "First, we need to observe the key and the door to understand how they interact. The key seems to be a standard key, and the\n",
      "\n",
      "Loading and testing model: Trained\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-Reasoning_trial_2_dist_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d526a15aa544cdba5e4697b27acae0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c0dcfe7cd44859bfaadc99087679bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key and unlock the door. I can help you with that. I can unlock the door for you.\n",
      "\n",
      "## Step 1: Understand the instruction\n",
      "The instruction is to pick up the key and unlock the door.\n",
      "\n",
      "## Step 2: Identify the role\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each model configuration to load and test with a simple query\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"\\nLoading and testing model: {model_name}\")\n",
    "\n",
    "    # Retrieve the loading function, model id, and optionally, the commit hash\n",
    "    load_fn = config[\"load_fn\"]\n",
    "    model_id = config[\"model_id\"]\n",
    "    revision = config.get(\"revision\", None)\n",
    "\n",
    "    # Load the model and associated tokenizer using the specified function\n",
    "    if load_fn.__name__ == \"load_base_model_with_vhead\":\n",
    "        model, tokenizer = load_fn(model_id)\n",
    "    else:\n",
    "        model, tokenizer = load_fn(model_id, revision)\n",
    "\n",
    "    # Simple query to test the model\n",
    "    prompt = \"You are in a room with a key. The instruction is to: pick up the key\"\n",
    "    \n",
    "    # Tokenize the input prompt and send tensors to device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generate output with your text-generation settings\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50, do_sample=True, temperature=0.7)\n",
    "\n",
    "    # Decode the generated tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Display the model's output\n",
    "    print(\"Model output:\")\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cuda if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Configuration parameters for text generation\n",
    "generation_kwargs = {\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.7,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the seen and unseen environments\n",
    "seen_env_ids = [\"BabyAI-GoTo-v0\", \"BabyAI-Pickup-v0\"]\n",
    "unseen_env_ids = [\"BabyAI-Open-v0\", \"BabyAI-PutNext-v0\", \"BabyAI-PickUpSeqGoTo-v0\"]\n",
    "\n",
    "# Reasoning flags list\n",
    "reasoning_flags = [True, False]\n",
    "\n",
    "# Number of parallel environments to instantiate for each configuration.\n",
    "num_envs = 6\n",
    "\n",
    "# Initialise a container for the aggregated results.\n",
    "evaluation_results = {}\n",
    "\n",
    "# Function that evaluates a model on a given environment and reasoning flag\n",
    "def evaluate_model_on_envs(env_id, reasoning_flag, model, tokenizer, generation_kwargs, device, num_episodes=50):\n",
    "    # Create environment managers for the current env_id and reasoning flag.\n",
    "    env_managers = [\n",
    "        EnvManager(\n",
    "            env_ids=[env_id],\n",
    "            invalid_action_penalty=-2,\n",
    "            consecutive_invalid_actions_allowed=5,\n",
    "            reasoning_flag=reasoning_flag,\n",
    "            num_dists=3,\n",
    "        )\n",
    "        for _ in range(num_envs)\n",
    "    ]\n",
    "    \n",
    "    # Run episodes using sample_episodes\n",
    "    stats, contexts = sample_episodes(\n",
    "        envs=env_managers,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        generation_kwargs=generation_kwargs,\n",
    "        device=device,\n",
    "        number_of_episodes=num_episodes,\n",
    "        context_window=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "    )\n",
    "    \n",
    "    # Calculate the summary metrics.\n",
    "    success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "    avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "    std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "    avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "    std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "    avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "    \n",
    "    # Bundle the results into a dictionary.\n",
    "    results = {\n",
    "        \"success_rate\": success_rate,\n",
    "        \"avg_reward\": avg_reward,\n",
    "        \"std_reward\": std_reward,\n",
    "        \"avg_episode_length\": avg_episode_length,\n",
    "        \"std_episode_length\": std_episode_length,\n",
    "        \"avg_num_invalid_actions\": avg_num_invalid_actions,\n",
    "        \"contexts\": contexts,  # optional: include detailed contexts if needed\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Baseline\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-Reasoning_trial_2_dist_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a362f073ef41e29456c93d0a0e0ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc41e1abae641b8964735ef99dd45bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Unseen env: BabyAI-Open-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Unseen env: BabyAI-Open-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Unseen env: BabyAI-PickUpSeqGoTo with reasoning=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:563: UserWarning: \u001b[33mWARN: Using the latest versioned environment `BabyAI-PickUpSeqGoTo-v0` instead of the unversioned environment `BabyAI-PickUpSeqGoTo`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Baseline on Unseen env: BabyAI-PickUpSeqGoTo with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Loading model: Trained\n",
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-Reasoning_trial_2_dist_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f109722bcca249aa9a4f93734b3a2cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d5c167e78c4c91b4a8e8ad28596708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Trained on Seen env: BabyAI-GoTo-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Seen env: BabyAI-GoTo-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Seen env: BabyAI-Pickup-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Seen env: BabyAI-Pickup-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Unseen env: BabyAI-Open-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Unseen env: BabyAI-Open-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Unseen env: BabyAI-PutNext-v0 with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Unseen env: BabyAI-PutNext-v0 with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Unseen env: BabyAI-PickUpSeqGoTo with reasoning=True\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Evaluating Trained on Unseen env: BabyAI-PickUpSeqGoTo with reasoning=False\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "\n",
      "Results for Baseline on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 0.98\n",
      "  Avg Reward: 0.85175 (Std: 0.18722812831401825)\n",
      "  Avg Episode Length: 10.5 (Std: 12.809833526611328)\n",
      "  Avg Num. of Invalid Actions: 0.1\n",
      "\n",
      "Results for Baseline on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 0.96\n",
      "  Avg Reward: 0.8311875000000002 (Std: 0.20685376226902008)\n",
      "  Avg Episode Length: 12.34 (Std: 14.047455787658691)\n",
      "  Avg Num. of Invalid Actions: 0.62\n",
      "\n",
      "Results for Baseline on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.9\n",
      "  Avg Reward: 0.8088750000000003 (Std: 0.2871154248714447)\n",
      "  Avg Episode Length: 13.04 (Std: 18.727869033813477)\n",
      "  Avg Num. of Invalid Actions: 0.16\n",
      "\n",
      "Results for Baseline on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 0.82\n",
      "  Avg Reward: 0.7271874999999999 (Std: 0.3533037304878235)\n",
      "  Avg Episode Length: 19.1 (Std: 23.702449798583984)\n",
      "  Avg Num. of Invalid Actions: 0.98\n",
      "\n",
      "Results for Baseline on BabyAI-Open-v0 (reasoning=True):\n",
      "  Success Rate: 0.06\n",
      "  Avg Reward: 0.03131249999999999 (Std: 0.13019812107086182)\n",
      "  Avg Episode Length: 126.28 (Std: 23.89948272705078)\n",
      "  Avg Num. of Invalid Actions: 4.44\n",
      "\n",
      "Results for Baseline on BabyAI-Open-v0 (reasoning=False):\n",
      "  Success Rate: 0.12\n",
      "  Avg Reward: 0.066984375 (Std: 0.19727058708667755)\n",
      "  Avg Episode Length: 131.54 (Std: 32.6866455078125)\n",
      "  Avg Num. of Invalid Actions: 11.36\n",
      "\n",
      "Results for Baseline on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 130.3 (Std: 2.589224100112915)\n",
      "  Avg Num. of Invalid Actions: 2.48\n",
      "\n",
      "Results for Baseline on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 133.36 (Std: 19.69124984741211)\n",
      "  Avg Num. of Invalid Actions: 7.92\n",
      "\n",
      "Results for Baseline on BabyAI-PickUpSeqGoTo (reasoning=True):\n",
      "  Success Rate: 0.44\n",
      "  Avg Reward: 0.39120312500000004 (Std: 0.45633000135421753)\n",
      "  Avg Episode Length: 79.02 (Std: 58.260318756103516)\n",
      "  Avg Num. of Invalid Actions: 0.4\n",
      "\n",
      "Results for Baseline on BabyAI-PickUpSeqGoTo (reasoning=False):\n",
      "  Success Rate: 0.42\n",
      "  Avg Reward: 0.38076562499999994 (Std: 0.4539647400379181)\n",
      "  Avg Episode Length: 84.22 (Std: 63.40388488769531)\n",
      "  Avg Num. of Invalid Actions: 4.4\n",
      "\n",
      "Results for Trained on BabyAI-GoTo-v0 (reasoning=True):\n",
      "  Success Rate: 0.98\n",
      "  Avg Reward: 0.855125 (Std: 0.1570052057504654)\n",
      "  Avg Episode Length: 10.18 (Std: 10.381872177124023)\n",
      "  Avg Num. of Invalid Actions: 0.02\n",
      "\n",
      "Results for Trained on BabyAI-GoTo-v0 (reasoning=False):\n",
      "  Success Rate: 0.92\n",
      "  Avg Reward: 0.80890625 (Std: 0.25518348813056946)\n",
      "  Avg Episode Length: 13.54 (Std: 16.356000900268555)\n",
      "  Avg Num. of Invalid Actions: 0.52\n",
      "\n",
      "Results for Trained on BabyAI-Pickup-v0 (reasoning=True):\n",
      "  Success Rate: 0.82\n",
      "  Avg Reward: 0.7285937500000003 (Std: 0.3493896424770355)\n",
      "  Avg Episode Length: 18.24 (Std: 22.511276245117188)\n",
      "  Avg Num. of Invalid Actions: 0.22\n",
      "\n",
      "Results for Trained on BabyAI-Pickup-v0 (reasoning=False):\n",
      "  Success Rate: 0.82\n",
      "  Avg Reward: 0.7454687500000001 (Std: 0.35515227913856506)\n",
      "  Avg Episode Length: 17.58 (Std: 23.435617446899414)\n",
      "  Avg Num. of Invalid Actions: 0.76\n",
      "\n",
      "Results for Trained on BabyAI-Open-v0 (reasoning=True):\n",
      "  Success Rate: 0.18\n",
      "  Avg Reward: 0.12853124999999999 (Std: 0.28445297479629517)\n",
      "  Avg Episode Length: 115.98 (Std: 36.521446228027344)\n",
      "  Avg Num. of Invalid Actions: 3.7\n",
      "\n",
      "Results for Trained on BabyAI-Open-v0 (reasoning=False):\n",
      "  Success Rate: 0.22\n",
      "  Avg Reward: 0.105109375 (Std: 0.2341914176940918)\n",
      "  Avg Episode Length: 126.72 (Std: 35.30279541015625)\n",
      "  Avg Num. of Invalid Actions: 10.54\n",
      "\n",
      "Results for Trained on BabyAI-PutNext-v0 (reasoning=True):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 130.0 (Std: 2.312344789505005)\n",
      "  Avg Num. of Invalid Actions: 2.0\n",
      "\n",
      "Results for Trained on BabyAI-PutNext-v0 (reasoning=False):\n",
      "  Success Rate: 0.0\n",
      "  Avg Reward: 0.0 (Std: 0.0)\n",
      "  Avg Episode Length: 138.04 (Std: 10.362727165222168)\n",
      "  Avg Num. of Invalid Actions: 10.04\n",
      "\n",
      "Results for Trained on BabyAI-PickUpSeqGoTo (reasoning=True):\n",
      "  Success Rate: 0.26\n",
      "  Avg Reward: 0.23525000000000001 (Std: 0.4016572833061218)\n",
      "  Avg Episode Length: 98.88 (Std: 51.2280387878418)\n",
      "  Avg Num. of Invalid Actions: 0.64\n",
      "\n",
      "Results for Trained on BabyAI-PickUpSeqGoTo (reasoning=False):\n",
      "  Success Rate: 0.46\n",
      "  Avg Reward: 0.38771875 (Std: 0.4361191689968109)\n",
      "  Avg Episode Length: 80.72 (Std: 55.83980178833008)\n",
      "  Avg Num. of Invalid Actions: 2.04\n"
     ]
    }
   ],
   "source": [
    "# Main Evaluation Loop\n",
    "for model_name, config in model_configs.items():\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    # Load model and tokenizer via the appropriate function.\n",
    "    if load_fn.__name__ == \"load_base_model_with_vhead\":\n",
    "        model, tokenizer = load_fn(model_id)\n",
    "    else:\n",
    "        model, tokenizer = load_fn(model_id, revision)\n",
    "    \n",
    "    # Update generation kwargs for this model. (Make sure you use its pad_token_id.)\n",
    "    local_generation_kwargs = {\n",
    "        \"max_new_tokens\": 20,\n",
    "        \"do_sample\": True,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.7,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    }\n",
    "    \n",
    "    # Loop over environments (seen and unseen) and reasoning flags.\n",
    "    # You can separate these groups as needed.\n",
    "    for env_group_name, env_ids in zip([\"Seen\", \"Unseen\"], [seen_env_ids, unseen_env_ids]):\n",
    "        for env_id in env_ids:\n",
    "            for reasoning in reasoning_flags:\n",
    "                print(f\"Evaluating {model_name} on {env_group_name} env: {env_id} with reasoning={reasoning}\")\n",
    "                results = evaluate_model_on_envs(\n",
    "                    env_id=env_id,\n",
    "                    reasoning_flag=reasoning,\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    generation_kwargs=local_generation_kwargs,\n",
    "                    device=device,\n",
    "                    num_episodes=50  # Adjust as needed.\n",
    "                )\n",
    "                # Save results with a composite key.\n",
    "                evaluation_results[(model_name, env_id, reasoning)] = results\n",
    "\n",
    "# --- Reporting the results ---\n",
    "for key, result in evaluation_results.items():\n",
    "    model_name, env_id, reasoning = key\n",
    "    print(f\"\\nResults for {model_name} on {env_id} (reasoning={reasoning}):\")\n",
    "    print(f\"  Success Rate: {result['success_rate']}\")\n",
    "    print(f\"  Avg Reward: {result['avg_reward']} (Std: {result['std_reward']})\")\n",
    "    print(f\"  Avg Episode Length: {result['avg_episode_length']} (Std: {result['std_episode_length']})\")\n",
    "    print(f\"  Avg Num. of Invalid Actions: {result['avg_num_invalid_actions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the evaluation results\n",
    "env_ids_to_plot = seen_env_ids + unseen_env_ids\n",
    "plot_performance_from_results(\n",
    "    env_ids=env_ids_to_plot,\n",
    "    evaluation_results=evaluation_results,\n",
    "    metric=\"success_rate\",\n",
    "    context_window=5,          # or any value used in your evaluation\n",
    "    env_type=\"All\", # \"Seen\" or \"Unseen\" or \"All\"\n",
    "    checkpoint_name=\"Final\"  # Adjust based on your models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 \n",
      "Summary: BabyAI-Pickup-v0 with Reasoning\n",
      "Sample size: 51\n",
      "Success Rate: 0.88\n",
      "Average Reward: 0.77 ± 0.29\n",
      "Average Episode Length: 15.47 ± 18.88\n",
      "Average Number of Invalid Actions: 0.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-PickupTest-v0 with Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.94\n",
      "Average Reward: 0.83 ± 0.22\n",
      "Average Episode Length: 11.80 ± 14.30\n",
      "Average Number of Invalid Actions: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-PickupTest-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3122648dc74dd6a28773c9d8eb7673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-No_Reasoning_trial_2_dist_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5b4495a2b94f5b879691bba8882782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561b3d11d7e040deb0a55be96fb83432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019c3dfa13b74994be19b5092a584852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/36.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b241bd9b547e4a85a81d61729f4b24cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"CatkinChen/final_runs-No_Reasoning_trial_2_dist_3\"\n",
    "revision = None # \"cf75726c11f5b5867107f56efc8f55439635f1c6\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer = load_model_with_peft_and_vhead(model_id, revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506b5084b7424cb5a712ce97209870b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.16\n",
      "Average Reward: 0.10 ± 0.25\n",
      "Average Episode Length: 28.28 ± 26.17\n",
      "Average Number of Invalid Actions: 4.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad2fa1a729d4d53a5953a80c88f14e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with No Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.38\n",
      "Average Reward: 0.24 ± 0.33\n",
      "Average Episode Length: 52.64 ± 22.58\n",
      "Average Number of Invalid Actions: 3.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with No Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.86\n",
      "Average Reward: 0.74 ± 0.33\n",
      "Average Episode Length: 17.80 ± 21.03\n",
      "Average Number of Invalid Actions: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-PickupTest-v0 with No Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.80\n",
      "Average Reward: 0.70 ± 0.36\n",
      "Average Episode Length: 19.98 ± 23.05\n",
      "Average Number of Invalid Actions: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-PickupTest-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning Train: Average Reward: 0.81 ± 0.26\n",
    "# Reasoning Test: Average Reward: 0.76 ± 0.32\n",
    "# Non-Reasoning Train: Average Reward: 0.74 ± 0.33\n",
    "# Non-Reasoning Test: Average Reward: 0.70 ± 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: BabyAI-Pickup-v0 with Reasoning (base model)\n",
    "# Sample size: 10\n",
    "# Success Rate: 0.50\n",
    "# Average Reward: 0.37 ± 0.40\n",
    "# Average Episode Length: 14.00 ± 9.76\n",
    "# Average Number of Invalid Actions: 3.60\n",
    "\n",
    "# Summary: BabyAI-Pickup-v0 with Reasoning (finetuned model but not run until convergence)\n",
    "# Sample size: 10\n",
    "# Success Rate: 0.70\n",
    "# Average Reward: 0.56 ± 0.41\n",
    "# Average Episode Length: 15.10 ± 10.79\n",
    "# Average Number of Invalid Actions: 2.50\n",
    "\n",
    "# Summary: BabyAI-Pickup-v0 with Reasoning (finetuned for longer)\n",
    "# Sample size: 12\n",
    "# Success Rate: 0.92\n",
    "# Average Reward: 0.80 ± 0.26\n",
    "# Average Episode Length: 9.33 ± 4.29\n",
    "# Average Number of Invalid Actions: 0.50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
