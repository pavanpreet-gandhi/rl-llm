{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /home/ubuntu/rl-llm\n",
      "Current directory: /home/ubuntu/rl-llm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if we're in the root directory of rl-llm repo\n",
    "if not os.path.basename(os.getcwd()) == 'rl-llm':\n",
    "    # If we're in a subdirectory of rl-llm, find the root and cd to it\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != 'rl-llm' and os.path.dirname(current_path) != current_path:\n",
    "        current_path = os.path.dirname(current_path)\n",
    "    \n",
    "    if os.path.basename(current_path) == 'rl-llm':\n",
    "        os.chdir(current_path)\n",
    "        print(f\"Changed directory to: {current_path}\")\n",
    "    else:\n",
    "        print(\"Not in rl-llm repository structure\")\n",
    "else:\n",
    "    print(\"Already in rl-llm root directory\")\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-GoTo-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Open-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-Pickup-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/ubuntu/rl-llm/.venv/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment BabyAI-PutNext-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "2025-04-12 21:19:22.514280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744492762.524234   10115 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744492762.529580   10115 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from src import EnvManager, sample_episodes\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from peft import PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-Reasoning_trial_2_dist_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60a372514dd453eaba073b4ffc10049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284c94dc100c4483a0b692811c44780f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model output:\n",
      "You are in a room with a key. The instruction is to: pick up the key and put it on the table. You then need to go to the door and open the door with the key. \n",
      "\n",
      "## Step 1: Pick up the key\n",
      "First, we need to pick up the key from the room.\n",
      "\n",
      "## Step \n"
     ]
    }
   ],
   "source": [
    "def load_model_with_peft_and_vhead(model_id, revision=None):\n",
    "    \"\"\"\n",
    "    Load a model with both PEFT adapters and value head\n",
    "    \n",
    "    Args:\n",
    "        model_id: Path to model or HF hub model ID\n",
    "        device: Device to load the model to\n",
    "        revision: Specific model revision/commit hash to load\n",
    "    \n",
    "    Returns:\n",
    "        model: The loaded model with adapters and value head\n",
    "        tokenizer: The associated tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get PEFT config to find base model\n",
    "    peft_config = PeftConfig.from_pretrained(model_id, revision=revision)\n",
    "    base_model_id = peft_config.base_model_name_or_path\n",
    "    \n",
    "    print(f\"Base model: {base_model_id}\")\n",
    "    print(f\"Loading with PEFT adapters from: {model_id}\")\n",
    "    if revision:\n",
    "        print(f\"Using revision: {revision}\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_id, padding_side='left')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Initialize model with value head from the base model\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        base_model_id,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # Now load the PEFT adapter weights\n",
    "    model = model.from_pretrained(model_id, device_map=\"auto\", revision=revision)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_base_model_with_vhead(model_id):\n",
    "    \"\"\"\n",
    "    Load a base model with value head\n",
    "    \n",
    "    Args:\n",
    "        model_id: Path to model or HF hub model ID\n",
    "    \n",
    "    Returns:\n",
    "        model: The loaded model with value head\n",
    "        tokenizer: The associated tokenizer\n",
    "    \"\"\"\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    print(f\"Loading base model with value head from: {model_id}\")\n",
    "    \n",
    "    # Initialize model with value head\n",
    "    model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model_id = \"CatkinChen/final_runs-Reasoning_trial_2_dist_3\"\n",
    "revision = None # \"cf75726c11f5b5867107f56efc8f55439635f1c6\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer = load_model_with_peft_and_vhead(model_id, revision)\n",
    "# model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "# Test the model with a simple query\n",
    "prompt = \"You are in a room with a key. The instruction is to: pick up the key\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=50, do_sample=True, temperature=0.7)\n",
    "print(\"\\nModel output:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.7,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.92\n",
      "Average Reward: 0.81 ± 0.26\n",
      "Average Episode Length: 14.08 ± 18.41\n",
      "Average Number of Invalid Actions: 1.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-PickupTest-v0 with Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.86\n",
      "Average Reward: 0.76 ± 0.32\n",
      "Average Episode Length: 15.74 ± 20.92\n",
      "Average Number of Invalid Actions: 1.20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-PickupTest-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Loading with PEFT adapters from: CatkinChen/final_runs-No_Reasoning_trial_2_dist_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bad0f6b536c4c3fb134e430d6be25de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2135647c1c784af9ab887bcfd159be2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"CatkinChen/final_runs-No_Reasoning_trial_2_dist_3\"\n",
    "revision = None # \"cf75726c11f5b5867107f56efc8f55439635f1c6\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer = load_model_with_peft_and_vhead(model_id, revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506b5084b7424cb5a712ce97209870b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.16\n",
      "Average Reward: 0.10 ± 0.25\n",
      "Average Episode Length: 28.28 ± 26.17\n",
      "Average Number of Invalid Actions: 4.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = True\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model with value head from: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad2fa1a729d4d53a5953a80c88f14e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-3B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with No Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.38\n",
      "Average Reward: 0.24 ± 0.33\n",
      "Average Episode Length: 52.64 ± 22.58\n",
      "Average Number of Invalid Actions: 3.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_base_model_with_vhead(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "\n",
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-Pickup-v0 with No Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.86\n",
      "Average Reward: 0.74 ± 0.33\n",
      "Average Episode Length: 17.80 ± 21.03\n",
      "Average Number of Invalid Actions: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-Pickup-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n",
      "Summary: BabyAI-PickupTest-v0 with No Reasoning\n",
      "Sample size: 50\n",
      "Success Rate: 0.80\n",
      "Average Reward: 0.70 ± 0.36\n",
      "Average Episode Length: 19.98 ± 23.05\n",
      "Average Number of Invalid Actions: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env_id = \"BabyAI-PickupTest-v0\"\n",
    "reasoning_flag = False\n",
    "env_ids = [env_id]\n",
    "num_envs = 6\n",
    "env_managers = [\n",
    "    EnvManager(\n",
    "        env_ids, \n",
    "        invalid_action_penalty=-2,\n",
    "        consecutive_invalid_actions_allowed=5,\n",
    "        reasoning_flag=reasoning_flag,\n",
    "        num_dists=3,\n",
    "    )\n",
    "    for i in range(num_envs)\n",
    "]\n",
    "\n",
    "stats, contexts = sample_episodes(\n",
    "    envs=env_managers,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    generation_kwargs=generation_kwargs,\n",
    "    device=device,\n",
    "    number_of_episodes=50,\n",
    "    context_window=5,\n",
    "    reasoning_flag=reasoning_flag,\n",
    ")\n",
    "success_rate = sum(stats[\"success\"]) / len(stats[\"success\"])\n",
    "avg_reward = sum(stats[\"rewards\"]) / len(stats[\"rewards\"])\n",
    "std_reward = torch.std(torch.tensor(stats[\"rewards\"], dtype=torch.float32)).item()\n",
    "avg_episode_length = sum(stats[\"episode_lengths\"]) / len(stats[\"episode_lengths\"])\n",
    "std_episode_length = torch.std(torch.tensor(stats[\"episode_lengths\"], dtype=torch.float32)).item()\n",
    "avg_num_invalid_actions = sum(stats[\"num_invalid_actions\"]) / len(stats[\"num_invalid_actions\"])\n",
    "\n",
    "print(f\"Summary: {env_id} with {'Reasoning' if reasoning_flag else 'No Reasoning'}\")\n",
    "print(f\"Sample size: {len(stats['success'])}\")\n",
    "print(f\"Success Rate: {success_rate:.2f}\")\n",
    "print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n",
    "print(f\"Average Episode Length: {avg_episode_length:.2f} ± {std_episode_length:.2f}\")\n",
    "print(f\"Average Number of Invalid Actions: {avg_num_invalid_actions:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning Train: Average Reward: 0.81 ± 0.26\n",
    "# Reasoning Test: Average Reward: 0.76 ± 0.32\n",
    "# Non-Reasoning Train: Average Reward: 0.74 ± 0.33\n",
    "# Non-Reasoning Test: Average Reward: 0.70 ± 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: BabyAI-Pickup-v0 with Reasoning (base model)\n",
    "# Sample size: 10\n",
    "# Success Rate: 0.50\n",
    "# Average Reward: 0.37 ± 0.40\n",
    "# Average Episode Length: 14.00 ± 9.76\n",
    "# Average Number of Invalid Actions: 3.60\n",
    "\n",
    "# Summary: BabyAI-Pickup-v0 with Reasoning (finetuned model but not run until convergence)\n",
    "# Sample size: 10\n",
    "# Success Rate: 0.70\n",
    "# Average Reward: 0.56 ± 0.41\n",
    "# Average Episode Length: 15.10 ± 10.79\n",
    "# Average Number of Invalid Actions: 2.50\n",
    "\n",
    "# Summary: BabyAI-Pickup-v0 with Reasoning (finetuned for longer)\n",
    "# Sample size: 12\n",
    "# Success Rate: 0.92\n",
    "# Average Reward: 0.80 ± 0.26\n",
    "# Average Episode Length: 9.33 ± 4.29\n",
    "# Average Number of Invalid Actions: 0.50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
