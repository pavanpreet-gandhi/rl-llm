\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{yao2023treethoughtsdeliberateproblem,yao2023react}
\citation{wang2023voyager}
\citation{carta2023grounding}
\citation{ouyang2022training}
\citation{deepseek2025r1,lambert2024t}
\citation{carta2023grounding}
\citation{carta2023grounding}
\citation{wei2022chain}
\citation{wang2022self}
\citation{yao2023treethoughtsdeliberateproblem}
\citation{nye2021show}
\citation{shinn2023reflexion}
\citation{ouyang2022training}
\citation{deepseek2025r1}
\citation{lambert2024t}
\citation{kazemnejad2024vineppo}
\citation{zelikman2022star}
\citation{xiang2025towards}
\citation{gandhi2025cognitive}
\citation{carta2023grounding}
\citation{yao2023react}
\citation{huang2022inner}
\citation{huang2022language}
\citation{ahn2022can}
\citation{kim2023language}
\citation{xiang2023language}
\citation{szot2024grounding}
\citation{wang2023voyager}
\citation{schick2023toolformer}
\citation{chen2025reinforcement}
\citation{gandhi2024stream}
\citation{carta2023grounding}
\citation{chevalier2018babyai}
\newlabel{subsec: 3.4}{{3.2}{3}{Prompt Design and Action Output}{subsection.3.2}{}}
\citation{carta2023grounding}
\citation{schulman2017proximal}
\citation{hu2021lora}
\citation{carta2023grounding}
\newlabel{subsec: PPO-based-LLM-fine-tuning}{{3.3}{4}{PPO-Based LLM Fine-tuning}{subsection.3.3}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:ppo}{{1}{5}{Nested PPO Training Loops for LLM's}{algorithm.1}{}}
\newlabel{subsec: 4.1}{{4.1}{6}{Performance Across Environment Configurations}{subsection.4.1}{}}
\newlabel{fig:three_distractors}{{1}{7}{Training curves for agents in environments with three distractors}{figure.caption.3}{}}
\newlabel{fig:reasoning_length}{{2}{7}{Average length of reasoning text (in words) generated by the reasoning agent over time during training in the 3-distractor environment}{figure.caption.4}{}}
\bibstyle{acl_natbib}
\bibdata{bibliography}
\bibcite{ahn2022can}{{1}{2022}{{Ahn et~al.}}{{Ahn, Brohan, Brown, Chebotar, Cortes, David, Finn, Fu, Gopalakrishnan, Hausman, Herzog, Ho, Hsu, Ibarz, Ichter, Irpan, Jang, Jauregui~Ruano, Jeffrey, Jesmonth, Joshi, Julian, Kalashnikov, Kuang, Lee, Levine, Lu, Luu, Parada, Pastor, Quiambao, Rao, Rettinghouse, Reyes, Sermanet, Sievers, Tan, Toshev, Vanhoucke, Xia, Xiao, Xu, Xu, Yan, and Zeng}}}
\newlabel{tab:performance3}{{1}{8}{Per-variant performance of reasoning and non-reasoning models in environments with three distractors}{table.caption.5}{}}
\bibcite{carta2023grounding}{{2}{2023}{{Carta et~al.}}{{Carta, Romac, Wolf, Lamprier, Sigaud, and Oudeyer}}}
\bibcite{chen2025reinforcement}{{3}{2025}{{Chen et~al.}}{{Chen, Cusumano-Towner, Huval, Petrenko, Hamburger, Koltun, and Kr{\"a}henb{\"u}hl}}}
\bibcite{chevalier2018babyai}{{4}{2018}{{Chevalier-Boisvert et~al.}}{{Chevalier-Boisvert, Bahdanau, Lahlou, Willems, Saharia, Nguyen, and Bengio}}}
\bibcite{deepseek2025r1}{{5}{2025}{{DeepSeek-AI et~al.}}{{DeepSeek-AI, Guo, Yang, Zhang et~al.}}}
\bibcite{gandhi2025cognitive}{{6}{2025}{{Gandhi et~al.}}{{Gandhi, Chakravarthy, Singh, Lile, and Goodman}}}
\bibcite{gandhi2024stream}{{7}{2024}{{Gandhi et~al.}}{{Gandhi, Lee, Grand, Liu, Cheng, Sharma, and Goodman}}}
\bibcite{hu2021lora}{{8}{2021}{{Hu et~al.}}{{Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen}}}
\bibcite{huang2022language}{{9}{2022}{{Huang et~al.}}{{Huang, Abbeel, Pathak, and Mordatch}}}
\bibcite{huang2022inner}{{10}{2023}{{Huang et~al.}}{{Huang, Xia, Xiao, Chan, Liang, Florence, Zeng, Tompson, Mordatch, Chebotar, Sermanet, Brown, Jackson, Luu, Levine, Hausman, and Ichter}}}
\bibcite{kazemnejad2024vineppo}{{11}{2024}{{Kazemnejad et~al.}}{{Kazemnejad, Aghajohari, Portelance, Sordoni, Reddy, Courville, and Roux}}}
\bibcite{kim2023language}{{12}{2023}{{Kim et~al.}}{{Kim, Baldi, and McAleer}}}
\bibcite{lambert2024t}{{13}{2024}{{Lambert et~al.}}{{Lambert, Morrison, Pyatkin, Huang, Ivison, Brahman, Miranda, Liu, Dziri, Lyu et~al.}}}
\bibcite{nye2021show}{{14}{2021}{{Nye et~al.}}{{Nye, Andreassen, Gur-Ari, Michalewski, Austin, Bieber, Dohan, Lewkowycz, Bosma, Luan, Sutton, and Odena}}}
\bibcite{ouyang2022training}{{15}{2022}{{Ouyang et~al.}}{{Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell, Welinder, Christiano, Leike, and Lowe}}}
\bibcite{schick2023toolformer}{{16}{2023}{{Schick et~al.}}{{Schick, Dwivedi-Yu, Dess{\`\i }, Raileanu, Lomeli, Hambro, Zettlemoyer, Cancedda, and Scialom}}}
\bibcite{schulman2017proximal}{{17}{2017}{{Schulman et~al.}}{{Schulman, Wolski, Dhariwal, Radford, and Klimov}}}
\bibcite{shinn2023reflexion}{{18}{2023}{{Shinn et~al.}}{{Shinn, Cassano, Gopinath, Narasimhan, and Yao}}}
\bibcite{szot2024grounding}{{19}{2024}{{Szot et~al.}}{{Szot, Mazoure, Agrawal, Hjelm, Kira, and Toshev}}}
\bibcite{wang2023voyager}{{20}{2023{a}}{{Wang et~al.}}{{Wang, Xie, Jiang, Mandlekar, Xiao, Zhu, Fan, and Anandkumar}}}
\bibcite{wang2022self}{{21}{2023{b}}{{Wang et~al.}}{{Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou}}}
\bibcite{wei2022chain}{{22}{2022}{{Wei et~al.}}{{Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou}}}
\bibcite{xiang2023language}{{23}{2023}{{Xiang et~al.}}{{Xiang, Tao, Gu, Shu, Wang, Yang, and Hu}}}
\bibcite{xiang2025towards}{{24}{2025}{{Xiang et~al.}}{{Xiang, Snell, Gandhi, Albalak, Singh, Blagden, Phung, Rafailov, Lile, Mahan et~al.}}}
\bibcite{yao2023treethoughtsdeliberateproblem}{{25}{2023{a}}{{Yao et~al.}}{{Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan}}}
\bibcite{yao2023react}{{26}{2023{b}}{{Yao et~al.}}{{Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao}}}
\bibcite{zelikman2022star}{{27}{2022}{{Zelikman et~al.}}{{Zelikman, Wu, Mu, and Goodman}}}
\newlabel{appendix: babyai-text}{{A}{11}{BabyAI-Text Example Interaction}{appendix.A}{}}
\newlabel{fig:babyai-example}{{3}{11}{Example of task, observation, and available actions in BabyAI-Text}{figure.caption.10}{}}
\newlabel{appendix:prompts}{{B}{12}{Prompts}{appendix.B}{}}
\newlabel{appendix:invalid_action}{{C}{13}{Invalid Action Regularisation}{appendix.C}{}}
\newlabel{appendix:chat_template}{{D}{15}{Chat Template Example}{appendix.D}{}}
\newlabel{appendix:choice_of_baseline}{{E}{16}{Choice of Baseline Model}{appendix.E}{}}
\newlabel{appendix:ppo_comp}{{F}{19}{Contextual Bandit v.s. Nested PPO}{appendix.F}{}}
\newlabel{fig:mc_td_reward_nonreasoning}{{8}{19}{Average Reward in Non-Reasoning Setup}{figure.caption.15}{}}
\newlabel{fig:mc_td_success_nonreasoning}{{9}{19}{Average Success Rate in Non-Reasoning Setup}{figure.caption.16}{}}
\newlabel{fig:mc_td_reward_reasoning}{{10}{20}{Average Reward in Reasoning Setup}{figure.caption.17}{}}
\newlabel{fig:mc_td_success_reasoning}{{11}{20}{Average Success Rate in Reasoning Setup}{figure.caption.18}{}}
\newlabel{appendix:hyperparameter}{{G}{21}{Hyperparameter Table}{appendix.G}{}}
\newlabel{appendix: training-curves}{{H}{22}{Training Curves}{appendix.H}{}}
\newlabel{fig:no_distractors}{{12}{22}{Training curves for agents in environments without distractors}{figure.caption.20}{}}
\newlabel{fig:five_distractors}{{13}{22}{Training curves for agents in environments with five distractors}{figure.caption.21}{}}
\newlabel{app:F}{{I}{23}{Evaluation Metrics}{appendix.I}{}}
\newlabel{tab:performance0}{{3}{23}{Summary statistics of zero-shot model and trained models on environments with 0 distractors}{table.caption.22}{}}
\newlabel{tab:performance5}{{4}{23}{Summary statistics of zero-shot model and trained models on environments with 5 distractors}{table.caption.23}{}}
\newlabel{app:Z}{{J}{27}{Model Performance on General Metrics}{appendix.J}{}}
\gdef \@abspage@last{27}
